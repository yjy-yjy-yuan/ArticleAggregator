"""
åˆå§‹åŒ– RSS æº

ä» OPML æ–‡ä»¶å¯¼å…¥ RSS æºå¹¶è§¦å‘é¦–æ¬¡æŠ“å–
"""

import sys
import os
from database import SessionLocal, engine, Base
from rss_manager import RSSSourceManager
from rss_fetcher import RSSFetcher

# åˆ›å»ºæ•°æ®åº“è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
print("ğŸ”§ æ£€æŸ¥å¹¶åˆ›å»ºæ•°æ®åº“è¡¨...")
Base.metadata.create_all(bind=engine)
print("âœ… æ•°æ®åº“è¡¨å·²å°±ç»ª\n")

# OPML æ–‡ä»¶è·¯å¾„ï¼ˆArticleAggregator_RSS_Articles.opmlï¼‰
OPML_FILE = os.path.join(
    os.path.dirname(os.path.dirname(__file__)),
    "ArticleAggregator_RSS_Articles.opml"
)


def init_rss_sources():
    """å¯¼å…¥ RSS æº"""
    print("=" * 60)
    print("ğŸ“š ArticleAggregator - RSS æºåˆå§‹åŒ–")
    print("=" * 60)

    if not os.path.exists(OPML_FILE):
        print(f"\nâŒ OPML æ–‡ä»¶ä¸å­˜åœ¨: {OPML_FILE}")
        print(f"\nè¯·ç¡®è®¤è·¯å¾„æ˜¯å¦æ­£ç¡®")
        return False

    db = SessionLocal()

    try:
        # 1. å¯¼å…¥ OPML
        print(f"\nğŸ“¥ æ­£åœ¨å¯¼å…¥ OPML æ–‡ä»¶...")
        print(f"   æ–‡ä»¶è·¯å¾„: {OPML_FILE}")

        manager = RSSSourceManager(db)
        stats = manager.import_from_opml(OPML_FILE)

        print(f"\nâœ… OPML å¯¼å…¥å®Œæˆ:")
        print(f"   æ€»æ•°: {stats['total']}")
        print(f"   æ–°å¢: {stats['new']}")
        print(f"   å·²å­˜åœ¨: {stats['existing']}")

        if stats['new'] == 0:
            print(f"\nâš ï¸  æ²¡æœ‰æ–°çš„ RSS æºï¼Œå¯èƒ½å·²ç»å¯¼å…¥è¿‡äº†")
            return True

        # 2. è¯¢é—®æ˜¯å¦ç«‹å³æŠ“å–
        print(f"\n" + "=" * 60)
        choice = input("æ˜¯å¦ç«‹å³æŠ“å–æ–‡ç« ï¼Ÿ(y/n): ").strip().lower()

        if choice == 'y':
            print(f"\nğŸš€ å¼€å§‹æŠ“å– RSS feed...")
            print(f"   æ¯ä¸ªæºæœ€å¤šæŠ“å– 10 ç¯‡æ–‡ç« ")

            fetcher = RSSFetcher(db)
            fetch_stats = fetcher.fetch_all_sources(max_articles_per_source=10)

            print(f"\nâœ… RSS æŠ“å–å®Œæˆ:")
            print(f"   æŠ“å–æºæ•°: {fetch_stats['sources_fetched']}")
            print(f"   æ–°æ–‡ç« æ•°: {fetch_stats['new_articles']}")
            print(f"   é”™è¯¯æ•°: {fetch_stats['errors']}")

            if fetch_stats['new_articles'] > 0:
                # 3. æå–å…¨æ–‡
                print(f"\n" + "=" * 60)
                extract_choice = input("æ˜¯å¦æå–æ–‡ç« å…¨æ–‡ï¼ˆè½¬æ¢ä¸º Markdownï¼‰ï¼Ÿ(y/n): ").strip().lower()

                if extract_choice == 'y':
                    print(f"\nğŸ“ å¼€å§‹æå–å…¨æ–‡...")
                    print(f"   ï¼ˆè¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼Œå–å†³äºæ–‡ç« æ•°é‡ï¼‰")

                    extract_stats = fetcher.extract_batch_content(limit=20)

                    print(f"\nâœ… å…¨æ–‡æå–å®Œæˆ:")
                    print(f"   å¤„ç†æ€»æ•°: {extract_stats['total']}")
                    print(f"   æˆåŠŸ: {extract_stats['success']}")
                    print(f"   å¤±è´¥: {extract_stats['failed']}")

        print(f"\n" + "=" * 60)
        print("ğŸ‰ åˆå§‹åŒ–å®Œæˆï¼")
        print(f"\nåç»­æŠ“å–å°†è‡ªåŠ¨è¿›è¡Œ:")
        print(f"   - RSS æŠ“å–: æ¯ 6 å°æ—¶")
        print(f"   - å…¨æ–‡æå–: æ¯ 30 åˆ†é’Ÿ")
        print(f"\nä½ ä¹Ÿå¯ä»¥é€šè¿‡ API æ‰‹åŠ¨è§¦å‘:")
        print(f"   POST http://localhost:8765/api/rss/fetch")
        print(f"   POST http://localhost:8765/api/rss/extract-content")
        print("=" * 60)

        return True

    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

    finally:
        db.close()


if __name__ == "__main__":
    success = init_rss_sources()
    sys.exit(0 if success else 1)
